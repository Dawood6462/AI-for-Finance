{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Machine Learning using tf.learn </h1>\n",
    "\n",
    "In this notebook, we will create a machine learning model using tf.learn and evaluate its performance.  The dataset is rather small (7700 samples), so we can do it all in-memory.  We will also simply pass the raw data in as-is. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.1\n"
     ]
    }
   ],
   "source": [
    "import datalab.bigquery as bq\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "print tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data created in the previous chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in CSV, target is the first column, after the features, followed by the key\n",
    "CSV_COLUMNS = ['fare_amount', 'pickuplon','pickuplat','dropofflon','dropofflat','passengers', 'key']\n",
    "FEATURES = CSV_COLUMNS[1:len(CSV_COLUMNS)-1]\n",
    "LABEL = CSV_COLUMNS[0]\n",
    "\n",
    "df_train = pd.read_csv('./taxi-train.csv', header=None, names=CSV_COLUMNS)\n",
    "df_valid = pd.read_csv('./taxi-valid.csv', header=None, names=CSV_COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Input function to read from Pandas Dataframe into tf.constant </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(df, num_epochs):\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "    x = df,\n",
    "    y = df[LABEL],\n",
    "    batch_size = 128,\n",
    "    num_epochs = num_epochs,\n",
    "    shuffle = True,\n",
    "    queue_capacity = 1000,\n",
    "    num_threads = 1\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create feature columns for estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_cols():\n",
    "  input_columns = [tf.contrib.layers.real_valued_column(k) for k in FEATURES]\n",
    "  return input_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Linear Regression with tf.learn Estimators framework </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1a2b621fd0>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': 'taxi_trained', '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:loss = 18664.4, step = 1\n",
      "INFO:tensorflow:global_step/sec: 384.476\n",
      "INFO:tensorflow:loss = 6258.93, step = 101 (0.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.337\n",
      "INFO:tensorflow:loss = 7155.71, step = 201 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.298\n",
      "INFO:tensorflow:loss = 11794.6, step = 301 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 386.813\n",
      "INFO:tensorflow:loss = 6829.92, step = 401 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.425\n",
      "INFO:tensorflow:loss = 13897.0, step = 501 (0.243 sec)\n",
      "INFO:tensorflow:global_step/sec: 427.305\n",
      "INFO:tensorflow:loss = 7813.46, step = 601 (0.234 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 608 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 51.2139.\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "shutil.rmtree('taxi_trained', ignore_errors=True) # start fresh each time\n",
    "model = tf.estimator.LinearRegressor(\n",
    "      feature_columns=make_feature_cols(), model_dir='taxi_trained')\n",
    "model.train(input_fn=make_input_fn(df_train, num_epochs = 10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on the validation data (we should defer using the test data to after we have selected a final model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2018-02-23-15:45:34\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-608\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-23-15:45:34\n",
      "INFO:tensorflow:Saving dict for global step 608: average_loss = 110.663, global_step = 608, loss = 13161.0\n",
      "RMSE on validation dataset = 114.721595764\n"
     ]
    }
   ],
   "source": [
    "def print_rmse(model, name, df):\n",
    "  metrics = model.evaluate(input_fn = make_input_fn(df, 1))\n",
    "  print 'RMSE on {} dataset = {}'.format(name, np.sqrt(metrics['loss']))\n",
    "print_rmse(model, 'validation', df_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is nowhere near our benchmark (RMSE of $6 or so on this data), but it serves to demonstrate what TensorFlow code looks like.  Let's use this model for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1a2aec0890>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': 'taxi_trained', '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-608\n",
      "[{'predictions': array([ 10.27550697], dtype=float32)}, {'predictions': array([ 10.27498817], dtype=float32)}, {'predictions': array([ 10.32199764], dtype=float32)}, {'predictions': array([ 10.46814823], dtype=float32)}, {'predictions': array([ 10.27688026], dtype=float32)}]\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "# read saved model and use it for prediction\n",
    "model = tf.estimator.LinearRegressor(\n",
    "      feature_columns=make_feature_cols(), model_dir='taxi_trained')\n",
    "preds_iter = model.predict(input_fn=make_input_fn(df_valid,1))\n",
    "print list(itertools.islice(preds_iter, 5)) # first 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This explains why the RMSE was so high -- the model essentially predicts $11 for every trip.  Would a more complex model help? Let's try using a deep neural network.  The code to do this is quite straightforward as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Deep Neural Network regression </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1a29fb8650>, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': 'taxi_trained', '_save_summary_steps': 100}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:loss = 18225.6, step = 1\n",
      "INFO:tensorflow:global_step/sec: 361.236\n",
      "INFO:tensorflow:loss = 16138.5, step = 101 (0.279 sec)\n",
      "INFO:tensorflow:global_step/sec: 457.015\n",
      "INFO:tensorflow:loss = 15309.7, step = 201 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.345\n",
      "INFO:tensorflow:loss = 10463.9, step = 301 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.969\n",
      "INFO:tensorflow:loss = 5849.55, step = 401 (0.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.73\n",
      "INFO:tensorflow:loss = 8680.56, step = 501 (0.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 469.982\n",
      "INFO:tensorflow:loss = 3287.35, step = 601 (0.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.643\n",
      "INFO:tensorflow:loss = 11661.8, step = 701 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.239\n",
      "INFO:tensorflow:loss = 5655.65, step = 801 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 425.166\n",
      "INFO:tensorflow:loss = 11266.1, step = 901 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 451.843\n",
      "INFO:tensorflow:loss = 8771.03, step = 1001 (0.222 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.592\n",
      "INFO:tensorflow:loss = 5002.24, step = 1101 (0.240 sec)\n",
      "INFO:tensorflow:global_step/sec: 448.895\n",
      "INFO:tensorflow:loss = 9581.76, step = 1201 (0.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 387.833\n",
      "INFO:tensorflow:loss = 14160.9, step = 1301 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 387.535\n",
      "INFO:tensorflow:loss = 16077.8, step = 1401 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.708\n",
      "INFO:tensorflow:loss = 8564.29, step = 1501 (0.275 sec)\n",
      "INFO:tensorflow:global_step/sec: 347.796\n",
      "INFO:tensorflow:loss = 9280.3, step = 1601 (0.288 sec)\n",
      "INFO:tensorflow:global_step/sec: 413.214\n",
      "INFO:tensorflow:loss = 12347.4, step = 1701 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 403.405\n",
      "INFO:tensorflow:loss = 15916.7, step = 1801 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 385.633\n",
      "INFO:tensorflow:loss = 12148.8, step = 1901 (0.258 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.159\n",
      "INFO:tensorflow:loss = 10731.3, step = 2001 (0.228 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.568\n",
      "INFO:tensorflow:loss = 10445.2, step = 2101 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 456.838\n",
      "INFO:tensorflow:loss = 10659.4, step = 2201 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 361.985\n",
      "INFO:tensorflow:loss = 11397.8, step = 2301 (0.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.276\n",
      "INFO:tensorflow:loss = 10845.3, step = 2401 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.417\n",
      "INFO:tensorflow:loss = 7216.61, step = 2501 (0.244 sec)\n",
      "INFO:tensorflow:global_step/sec: 389.613\n",
      "INFO:tensorflow:loss = 7724.1, step = 2601 (0.256 sec)\n",
      "INFO:tensorflow:global_step/sec: 405.07\n",
      "INFO:tensorflow:loss = 7395.99, step = 2701 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 408.215\n",
      "INFO:tensorflow:loss = 6889.63, step = 2801 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 442.625\n",
      "INFO:tensorflow:loss = 8383.42, step = 2901 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 454.368\n",
      "INFO:tensorflow:loss = 11190.4, step = 3001 (0.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 371.923\n",
      "INFO:tensorflow:loss = 11395.8, step = 3101 (0.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.743\n",
      "INFO:tensorflow:loss = 14309.1, step = 3201 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 390.848\n",
      "INFO:tensorflow:loss = 10196.3, step = 3301 (0.257 sec)\n",
      "INFO:tensorflow:global_step/sec: 383.937\n",
      "INFO:tensorflow:loss = 9528.87, step = 3401 (0.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 353.433\n",
      "INFO:tensorflow:loss = 12292.7, step = 3501 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.086\n",
      "INFO:tensorflow:loss = 11060.4, step = 3601 (0.280 sec)\n",
      "INFO:tensorflow:global_step/sec: 357.901\n",
      "INFO:tensorflow:loss = 6600.06, step = 3701 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 412.215\n",
      "INFO:tensorflow:loss = 8629.72, step = 3801 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 406.274\n",
      "INFO:tensorflow:loss = 8013.09, step = 3901 (0.245 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.007\n",
      "INFO:tensorflow:loss = 10435.2, step = 4001 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 428.267\n",
      "INFO:tensorflow:loss = 11347.9, step = 4101 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.688\n",
      "INFO:tensorflow:loss = 8591.91, step = 4201 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 441.468\n",
      "INFO:tensorflow:loss = 8819.48, step = 4301 (0.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.025\n",
      "INFO:tensorflow:loss = 9911.14, step = 4401 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 401.213\n",
      "INFO:tensorflow:loss = 13462.1, step = 4501 (0.249 sec)\n",
      "INFO:tensorflow:global_step/sec: 400.529\n",
      "INFO:tensorflow:loss = 10710.6, step = 4601 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 422.301\n",
      "INFO:tensorflow:loss = 20651.5, step = 4701 (0.236 sec)\n",
      "INFO:tensorflow:global_step/sec: 431.874\n",
      "INFO:tensorflow:loss = 9084.57, step = 4801 (0.231 sec)\n",
      "INFO:tensorflow:global_step/sec: 401.836\n",
      "INFO:tensorflow:loss = 12552.2, step = 4901 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.354\n",
      "INFO:tensorflow:loss = 7787.08, step = 5001 (0.252 sec)\n",
      "INFO:tensorflow:global_step/sec: 397.303\n",
      "INFO:tensorflow:loss = 15201.3, step = 5101 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 384.562\n",
      "INFO:tensorflow:loss = 7336.93, step = 5201 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 362.429\n",
      "INFO:tensorflow:loss = 18347.4, step = 5301 (0.273 sec)\n",
      "INFO:tensorflow:global_step/sec: 434.811\n",
      "INFO:tensorflow:loss = 7346.91, step = 5401 (0.233 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.007\n",
      "INFO:tensorflow:loss = 6466.35, step = 5501 (0.251 sec)\n",
      "INFO:tensorflow:global_step/sec: 407.651\n",
      "INFO:tensorflow:loss = 13323.7, step = 5601 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 402.475\n",
      "INFO:tensorflow:loss = 9914.92, step = 5701 (0.248 sec)\n",
      "INFO:tensorflow:global_step/sec: 423.368\n",
      "INFO:tensorflow:loss = 11923.1, step = 5801 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 406.025\n",
      "INFO:tensorflow:loss = 5358.47, step = 5901 (0.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 438.078\n",
      "INFO:tensorflow:loss = 5248.89, step = 6001 (0.229 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6071 into taxi_trained/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 3459.57.\n",
      "INFO:tensorflow:Starting evaluation at 2018-02-23-15:46:34\n",
      "INFO:tensorflow:Restoring parameters from taxi_trained/model.ckpt-6071\n",
      "INFO:tensorflow:Finished evaluation at 2018-02-23-15:46:35\n",
      "INFO:tensorflow:Saving dict for global step 6071: average_loss = 109.444, global_step = 6071, loss = 13016.0\n",
      "RMSE on validation dataset = 114.087715149\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "shutil.rmtree('taxi_trained', ignore_errors=True) # start fresh each time\n",
    "model = tf.estimator.DNNRegressor(hidden_units=[32, 8, 2],\n",
    "      feature_columns=make_feature_cols(), model_dir='taxi_trained')\n",
    "model.train(input_fn=make_input_fn(df_train, num_epochs=100));\n",
    "print_rmse(model, 'validation', df_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not beating our benchmark with either model ... what's up?  Well, we may be using TensorFlow for Machine Learning, but we are not yet using it well.  That's what the rest of this course is about!\n",
    "\n",
    "But, for the record, let's say we had to choose between the two models. We'd choose the one with the lower validation error. Finally, we'd measure the RMSE on the test data with this chosen model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Benchmark dataset </h2>\n",
    "\n",
    "Let's do this on the benchmark dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "DefaultCredentialsError",
     "evalue": "Could not automatically determine credentials. Please set GOOGLE_APPLICATION_CREDENTIALS or\nexplicitly create credential and re-run the application. For more\ninformation, please see\nhttps://developers.google.com/accounts/docs/application-default-credentials.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDefaultCredentialsError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-05ad91e7db17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQuery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0mprint_rmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'benchmark'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ajinkyak/anaconda2/lib/python2.7/site-packages/datalab/bigquery/_query.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sql, context, values, udfs, data_sources, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m       \"\"\"\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m       \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatalab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ajinkyak/anaconda2/lib/python2.7/site-packages/datalab/context/_context.pyc\u001b[0m in \u001b[0;36mdefault\u001b[0;34m()\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mAn\u001b[0m \u001b[0minitialized\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mshared\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0ma\u001b[0m \u001b[0mContext\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \"\"\"\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mcredentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_credentials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_global_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mproject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_project\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ajinkyak/anaconda2/lib/python2.7/site-packages/datalab/context/_utils.pyc\u001b[0m in \u001b[0;36mget_credentials\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No application credentials found. Perhaps you should sign in.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDefaultCredentialsError\u001b[0m: Could not automatically determine credentials. Please set GOOGLE_APPLICATION_CREDENTIALS or\nexplicitly create credential and re-run the application. For more\ninformation, please see\nhttps://developers.google.com/accounts/docs/application-default-credentials."
     ]
    }
   ],
   "source": [
    "import datalab.bigquery as bq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def create_query(phase, EVERY_N):\n",
    "  \"\"\"\n",
    "  phase: 1=train 2=valid\n",
    "  \"\"\"\n",
    "  base_query = \"\"\"\n",
    "SELECT\n",
    "  (tolls_amount + fare_amount) AS fare_amount,\n",
    "  CONCAT(STRING(pickup_datetime), STRING(pickup_longitude), STRING(pickup_latitude), STRING(dropoff_latitude), STRING(dropoff_longitude)) AS key,\n",
    "  DAYOFWEEK(pickup_datetime)*1.0 AS dayofweek,\n",
    "  HOUR(pickup_datetime)*1.0 AS hourofday,\n",
    "  pickup_longitude AS pickuplon,\n",
    "  pickup_latitude AS pickuplat,\n",
    "  dropoff_longitude AS dropofflon,\n",
    "  dropoff_latitude AS dropofflat,\n",
    "  passenger_count*1.0 AS passengers,\n",
    "FROM\n",
    "  [nyc-tlc:yellow.trips]\n",
    "WHERE\n",
    "  trip_distance > 0\n",
    "  AND fare_amount >= 2.5\n",
    "  AND pickup_longitude > -78\n",
    "  AND pickup_longitude < -70\n",
    "  AND dropoff_longitude > -78\n",
    "  AND dropoff_longitude < -70\n",
    "  AND pickup_latitude > 37\n",
    "  AND pickup_latitude < 45\n",
    "  AND dropoff_latitude > 37\n",
    "  AND dropoff_latitude < 45\n",
    "  AND passenger_count > 0\n",
    "  \"\"\"\n",
    "\n",
    "  if EVERY_N == None:\n",
    "    if phase < 2:\n",
    "      # training\n",
    "      query = \"{0} AND ABS(HASH(pickup_datetime)) % 4 < 2\".format(base_query)\n",
    "    else:\n",
    "      query = \"{0} AND ABS(HASH(pickup_datetime)) % 4 == {1}\".format(base_query, phase)\n",
    "  else:\n",
    "      query = \"{0} AND ABS(HASH(pickup_datetime)) % {1} == {2}\".format(base_query, EVERY_N, phase)\n",
    "    \n",
    "  return query\n",
    "\n",
    "\n",
    "\n",
    "query = create_query(2, 100000)\n",
    "df = bq.Query(query).to_dataframe()\n",
    "print_rmse(model, 'benchmark', df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE on benchmark dataset is <b>9.41</b> (your results will vary because of random seeds).\n",
    "\n",
    "This is not only way more than our original benchmark of 6.00, but it doesn't even beat our distance-based rule's RMSE of 8.02.\n",
    "\n",
    "Fear not -- you have learned how to write a TensorFlow model, but not to do all the things that you will have to do to your ML model performant. We will do this in the next chapters. In this chapter though, we will get our TensorFlow model ready for these improvements.\n",
    "\n",
    "In a software sense, the rest of the labs in this chapter will be about refactoring the code so that we can improve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2017 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
